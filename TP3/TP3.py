import numpy
import os
import codecs
import re
import nltk
from nltk.corpus import stopwords

def remove_stopword(phrase):
    aux_list = numpy.array([])
    stoplist = stopwords.words('english')
    #print(phrase)
    #print(stoplist)
    for word in phrase :
        if word.lower() not in stoplist:
            #PROBLEME ICI : On arrive pas à avoir la liste des mots, on garde juste le dernier au niveau du return
 #           print(stoplist)
            aux_list = numpy.append(aux_list, [word])
#            print(aux_list)

#    print(aux_list)
    return aux_list
#On suppose qu'on a un texte qui est une liste de phrases
# Ces phrases sont des phrases sans stopword, sans ponctuation
# et considérées comme une liste de mot (liste de liste)
def tfidf_dict(texte):
    dict_tf={}
    dict_idf={}
    compt = 0
    for phrase in texte :
        vu = []
        compt += len(phrase)
        for mot in phrase :

            if mot in dict_tf:
                dict_tf[mot]+=1
                if mot not in vu :
                    vu.append(mot)
            else:
                dict_tf[mot]=1
                if mot not in vu :
                    vu.append(mot)
        for apparition in vu:
            if apparition in dict_idf:
                dict_idf[apparition] += 1
            else:
                dict_idf[apparition] = 1
    dict_res = {}
    for mot in dict_idf:
        dict_res[mot] = (dict_tf[mot]/compt )*( dict_idf[mot]/len(texte))
    return dict_res
'''
def tfidf(mot, texte):
    compt_mot = 0
    compt_tot = 0
    nbi=0
    compt_phrase = 0

    for sentence in texte :
        present = 0
        for word in sentence:
            if word == mot:
                present = 1
                compt_mot+=1
            compt_tot+=1
        nbi += present
        compt_phrase += 1
    tf = compt_mot/compt_tot
    if nbi != 0 :
        idf = compt_phrase / nbi
    else:
        return -10000
    return tf*idf
'''
def poids_phrase(phrase, corpus):
    # C'est ici qu'on peut améliorer
    compt = 0
    for mot in phrase:
        compt = tfidf(mot,corpus)
    return compt / len(phrase)

def resume(k,corpus):
    list_resume = []
    dict_tfidf = tfidf_dict(corpus)
    list_indic=numpy.array([])
    for i in range(k):
        vec_poids = numpy.array([])
        for phrase in corpus:
            poids_phrase = 0
            for mot in remove_stopword(phrase) :
                poids_phrase += dict_tfidf[mot]
            vec_poids = numpy.append(vec_poids, poids_phrase/len(phrase))
        aux = vec_poids[0]
        for i in range(len(vec_poids)):
            if vec_poids[i]> aux and i not in list_indic:
                aux = vec_poids[i]
                indice = i
        list_indic = numpy.append(list_indic,indice)
        list_resume.append(corpus[indice])
        numpy.delete(corpus,indice)
    return list_resume




def lect_text(path):
    text = numpy.array([])
    for x in open(path,"r").readlines():
        text = numpy.append(text, x)
    return text


list_files=numpy.array([])

list_sys=numpy.array([])


#def get_files(folder_path):
for _,_,file in os.walk("./Critiques/projects/test-summarization/topics/"):
    list_files = numpy.append(list_files,file)
for _,_,file in os.walk("./Critiques/projects/test-summarization/system/"):
    list_sys = numpy.append(list_sys, file)
print(list_files)
print(list_sys)
for i in range(len(list_files)) :
    list_phrase = []
    for x in open("./Critiques/projects/test-summarization/topics/" + list_files[i],"r+", encoding="ISO-8859-1").readlines():
        # list_phrase = numpy.append(list_phrase, numpy.array(re.sub(r"[\n,.]+", ' ', x).split()))
        list_phrase.append(numpy.array(re.sub(r"[\n,!,?,.]+", ' ', x).split()))
    list_phrase = numpy.array(list_phrase)
    #  print(tfidf_dict(list_phrase))
    coucou = (resume(5,list_phrase))
    print(list_files[i])
    for coucoux in coucou :
        print(coucoux)
    print("")
    #print(list_phrase)
    #f = open("./Critiques/projects/test-summarization/system/" +list_sys[i],"a")
    #f.write(str(resume(5, list_phrase)))
    #f.close()
    #print(list_phrase)
    #for phrase in list_phrase:

    # print(list_phrase)
    #print(phrase)
    #remove_stopword(phrase.split())

'''
list_aux = []
for x in open("./Critiques/projects/test-summarization/topics/speed_windows7.txt.data", "r+", encoding="ISO-8859-1").readlines():
    list_aux.append(re.sub(r"[\n,.]+", ' ', x).split())


print(resume(5, list_aux))

'''

