import math
import re
import numpy as np
from nltk.corpus import stopwords
import matplotlib.pyplot as plt
import nltk
from sklearn.decomposition import PCA
# Uniquement pour ignorer les "FutureWarning " exception
import warnings


# Renvoie le vocabulaire du texte
def get_voc(texte):
    """
        :param texte: texte: list de mots sans les charactères spéciaux
        ("/n", ".", "?"...)
        :return:dict_voc : un dictionnaire contenant la liste des mots uniques
        du texte ainsi que leur indice dans la matrice de PPMI
    """
    list_voc = np.array([])
    for i in texte :
        if i not in list_voc :
            list_voc = np.append(list_voc,i)

    return list_voc


# Renvoie le vocabulaire du texte sans les stop words
def get_voc_nostopword(texte):
    """
    :param texte: texte: list de mots sans les charactères spéciaux
    ("/n", ".", "?"...)
    :return:dict_voc : un dictionnaire contenant la liste des mots uniques
    et sans les stop words du texte ainsi que leur indice dans
    la matrice de PPMI
    """
    dict_voc = {}
    indic = 0
    stop_words = stopwords.words('french')
    stop_words.append("a")
    for mot in texte :
        if mot.lower() not in stop_words:
            if mot not in dict_voc :
                dict_voc[mot]=indic
                indic+=1
    return dict_voc


# Calcul de la valeur de PPMI de chacun des mots avec chacun des autres mots
# sans les stopwords et renvoie un dictionnaire
def dic_PPMI_all(texte):
    '''

    :param texte: list de mots sans les charactères spéciaux
    ("/n", ".", "?"...)

    :return: dic_ppmi : un dictionnaire contenant chaque mot du
    vocabulaire comme clé. Chaque valeur pour ces clés sont des
    dictionnaires contenant comme clés les mots rencontrés conjointement
    avec le premier mot. La valeur associée à cette 2nd clé est la PPMI
    entre les deux mots
    '''
    taille_fenetre = 5
    stop_words = stopwords.words('french')
    # à devient A au début des phrases; en miniscule cela devient a
    stop_words.append("a")
    dic_ppmi = {}
    nb_appa = {}
    nb_mot = 0
    nb_fenetre = 0

    for mot in texte :
        if mot.lower() not in stop_words:
            nb_appa[mot] = 0
            dic_ppmi[mot] = {}
    for indice_texte in range(len(texte)):
        # pour un indice, utiliser (len(texte)-1)
        fenetre=np.array([])
        # On compte le premier mot de chaque fenêtre
        if texte[indice_texte].lower() not in stop_words:
            nb_appa[texte[indice_texte]] += 1

        # taille_fenetre -1 : on travaille avec des indice et taille de fenêtre est une taille
        # les indices commencent à 0 et les taille à 1
        if indice_texte+(taille_fenetre-1) < len(texte):
            for aux in range(taille_fenetre):
                fenetre = np.append(fenetre, texte[indice_texte+aux])
            nb_fenetre+=1
            # Range crée un tableau de 0 à taille_fenêtre -1 : ici 0 à 4
            # (de taille 5)
            for i in range(taille_fenetre):
                for j in range(i+1, taille_fenetre):
                    if fenetre[i].lower() not in stop_words and fenetre[j].lower() not in stop_words:

                        if fenetre[j] not in dic_ppmi[fenetre[i]]:
                            dic_ppmi[fenetre[i]][fenetre[j]] = 1
                            dic_ppmi[fenetre[j]][fenetre[i]] = 1
                            # On ne compte que les mots qu'on considère
                            nb_mot +=1
                        else:
                            dic_ppmi[fenetre[i]][fenetre[j]] += 1
                            dic_ppmi[fenetre[j]][fenetre[i]] += 1
                            # On ne compte que les mots qu'on considère
                            nb_mot +=1
    for key in dic_ppmi:
        for mot in dic_ppmi[key]:
            pkey = nb_appa[key]/len(texte)
            pmot = nb_appa[mot]/len(texte)
            # On peut car seul les mots vu conjointements sont inscrit dans le dictionnaire
            # On n'a donc pas de problème pour le log car tous les mots possèdent une probabilité
            # conjointe supérieure à 0
            dic_ppmi[key][mot] = np.log((dic_ppmi[key][mot] / nb_fenetre ) / ( pkey * pmot ))
    return dic_ppmi
# FIN VERSION AVEC DICTIONNAIRE


# Calcul de la matrice de PPMI pour tous les mots de tout le texte et
# retourne une matrice de taille n*n (n : la taille du vocabulaire sans
# les stopwords )
def mat_PPMI_all(texte):
    """
    :param texte: list de mots sans les charactères spéciaux
    ("/n", ".", "?"...)

    :return: (mat_ppmi , voc) : retourn la matrice des PPMI de chacun des
    mots et un dictionnaire contenant la liste des mots et leur indice
    sous la forme d'un doublet
    """

    taille_fenetre = 5
    stop_words = stopwords.words('french')
    # à devient A au début des phrases; en miniscule cela devient a
    stop_words.append("a")
    voc = get_voc_nostopword(texte)
    mat_ppmi = np.zeros((len(voc),len(voc)))

    nb_appa = {}
    nb_mot = 0
    nb_fenetre = 0
    for mot in texte :
        if mot.lower() not in stop_words:
            nb_appa[mot] = 0
    for indice_texte in range(len(texte)):
        # pour un indice, utiliser (len(texte)-1)
        fenetre=np.array([])
        # On compte le premier mot de chaque fenêtre
        if texte[indice_texte].lower() not in stop_words:
            mat_ppmi[voc[texte[indice_texte]]][voc[texte[indice_texte]]] += 1

        # taille_fenetre -1 : on travaille avec des indice et taille de fenêtre est une taille
        # les indices commencent à 0 et les taille à 1
        if indice_texte+(taille_fenetre-1) < len(texte):
            for aux in range(taille_fenetre):
                fenetre = np.append(fenetre, texte[indice_texte+aux])
            nb_fenetre+=1
            # Range crée un tableau de 0 à taille_fenêtre -1 : ici 0 à 4
            # (de taille 5)

            for i in range(taille_fenetre):
                if fenetre[i].lower() not in stop_words:
                    for j in range(i+1, taille_fenetre):
                        #print(fenetre[j].lower())
                        if fenetre[j].lower() not in stop_words:
                            mat_ppmi[voc[fenetre[i]]][voc[fenetre[j]]]+=1
    for i in range(len(voc)):
        nb_mot += mat_ppmi[i][i]
    for i in range(len(voc)):
        for j in range(i+1,len(voc)):
            if mat_ppmi[i][j] > 0 :
                mat_ppmi[i][j]=np.log(mat_ppmi[i][j]/((mat_ppmi[i][i]/nb_mot )*(mat_ppmi[j][j]/nb_mot) ))

    return mat_ppmi , voc


# Affichage des vecteurs de PPMI de mots d'un texte
# Les vecteurs de PPMI étant de dimension >3, une PCA est réalisée
# afin de réduire la dimensionnalité des vecteurs.
# Sauvegarde dans le fichier foo.png et affichage à l'écran
def aff_mat_ppmi(mat_ppmi,voc, list_word=None):
    """

    :param mat_ppmi: matrice des PPMI de chacun des mots avec les autres
    mots du texte
    :param voc: dictionnaire contenant les mots et leur indice
    dans la matrice de PPMI
    :param list_word: (optionnel) liste des mots à afficher
    :return:
    """
    if list_word != None :
        list_toprint =[]
        for mot in list_word:
            list_toprint.append(voc[mot])
    else:
        list_toprint=[]
        for mot in voc :
            list_toprint.append(voc[mot])
    voc_aux = []
    mat_aux =[]
    for i in list_toprint:
        mat_aux.append(mat_ppmi[i])
        voc_aux.append(list(voc.keys())[i])
    pca = PCA(n_components=2)
    Xp = pca.fit_transform(mat_aux)
    print(Xp)
    list_x=[]
    list_y=[]
    for i in range(len(Xp)):
        list_x.append(Xp[i][0])
        list_y.append(Xp[i][1])
    print(list_x,list_y)
    print(voc_aux)
    plt.plot(list_x, list_y, 'ro')
    plt.axis([np.min(list_x)-1, np.max(list_x)+1,np.min(list_y)-1,np.max(list_y)+1])
    plt.savefig('foo.png')
    plt.show()



# Fonction de calcul de PPMI entre 2 mots pour un texte avec fenêtre glissante
def PPMI (x, y, texte):
    """

    :param x: string : premier mot pour le calcul de PPMI
    :param y: string : second mot pour le calcul de PPMI
    :param texte: liste de mots sur lequel calculer la PPMI de 2 mots
    :return: la valeur de la PPMI pour 2 mots
    """
    # INITIALISATION
    # Taille des fenêtres de mots : MODIFIER ICI LA TAILLE DE FENETRE
    taille_fenetre=5

    # Vecteurs d'occurence de X, de Y et d'occurrences simultannées de X et Y
    occur_x = np.array([])
    occur_y = np.array([])
    occur_xy = np.array([])

    # BODY
    # Début lecture texte
    # Pour un curseur allant de 0 à taille(texte)-1
    # (-1 car les tableaux commencent à 0 et non à 1)
    for curseur in range((len(texte)-1)):

        # Remise à 0 des compteurs d'occurences de (X,Y), X et Y
        Tfxy = 0
        Tfx = 0
        Tfy = 0
        # Fenêtre glissante
        fenetre_aux=np.array([])

        # Construction des fenêtres
        # On veut récupérer les 5 mots du texte à partir du curseurs soit :
        # fenetre_aux = [texte[curseur],texte[curseur+1],
        # texte[curseur+2],texte[curseur+3],texte[curseur+4]]

        # Pour i allant de 0 à la taille de la fenêtre
        for i in range(taille_fenetre):
            # Si le curseur dépasse du texte
            # len(texte)-1 : les indices commencent à 0 tandis que la taille commence à 1
            # donc il faut soustraire 1 pour que cela coïncide
            if i+curseur > len(texte)-1:
                # On sort
                break
            # Ajout du mot dans la fenêtre
            fenetre_aux = np.append(fenetre_aux, texte[i + curseur ])
        # Remise à 0 du booléen
        pas_vu = True
        # Pour tous les mots de la fenêtre actuelle
        for mot in fenetre_aux:

            # Si le mot considéré est le mot X
            if mot == x :
                # Incrémentation du compteur de X
                Tfx += 1

            # Si le mot considéré est le mot Y
            if mot == y :
                # Incrémentation du compteur de Y
                Tfy +=1
            # Si le mot X et le mot Y ont été rencontré dans cette fenêtre
            # et si c'est la première fois qu'ils ont été compté
            if Tfx >= 1 and Tfy >= 1  and pas_vu  :
                # On met le compte à 1
                Tfxy = 1
                # On indique que le mot a déjà été compté
                pas_vu = False

        # Soit notre fenêtre glissantes :
        # fenêtre = [mot1, mot2, mot3, mot4, mot5]

        # Ajout du nombre d'apparition de x et y dans leur vecteur correspondants
        occur_x = np.append(occur_x, Tfx)
        occur_y = np.append(occur_y, Tfy)
        # Ajout du nombre d'apparition conjointes de x et y
        occur_xy = np.append(occur_xy, Tfxy)

    # Réinitialisation des compteurs
    Tfxy = 0
    Tfy=0
    Tfx=0

    # Comptage du total d'apparition de X dans les N contextes
    for apparition in occur_x :
        Tfx += apparition
    # Comptage du total d'apparition de Y dans les N contextes
    for apparition in occur_y :
        Tfy += apparition
    # Comptage du total d'apparition conjointe de X et Y dans les N contextes
    for apparition in occur_xy :
        Tfxy += apparition

    # Compteur du nombre d'occurences de X et Y
    occurences_total = Tfx + Tfy

    Pxy = Tfxy / len(occur_x)

    # Probabilité d'avoir X  (correspond à la fréquence de X ?)
    Px = Tfx / len(occur_x)

    # Probabilité d'avoir Y  (correspond à la fréquence de Y ?)
    Py = Tfy / len(occur_x)

    base_log = 10
    if (Pxy / (Px * Py)) > 0:
        return math.log((Pxy / (Px * Py)), base_log)
    else:
        return 0




if __name__ == '__main__':

    warnings.simplefilter(action='ignore', category=FutureWarning)

    nltk.download('stopwords')
    text = "A chaque ville, son explication. Les gares sur l’axe Atlantique (Toulouse, " \
           "Tours et Bordeaux) ont par exemple été touchées par les travaux de la LGV Sud-Europe Atlantique, " \
           "reliant Paris à Bordeaux en 2h04, inaugurée au début du mois de juillet." \
           " Toulouse, relié à Paris via Bordeaux en TGV, a donc fait les frais de cette entreprise, débutée en 2012."

    # Suppression de tous les caractères qui ne sont pas : de a à z, de A à Z,
    # de 0 à 9, de "à" à "é", de "é" à "è" (cf codage ASCII)
    text_aux = re.sub(r"[^a-zA-Z0-9-à-é-è]+", ' ', text)
    print(text_aux)
    text_formate = text_aux.split()
    print(text_formate)

    res = PPMI("Bordeaux","Toulouse",text_formate)


    # Permet d'obtenir le vocabulaire du texte :
    # la liste des mots uniques du texte
    voc = get_voc(text_formate)
    #print(text_formate)
    #print(mat_PPMI_all(text_formate))
    mat,voc = mat_PPMI_all(text_formate)

    aff_mat_ppmi(mat,voc )

