import pandas as pd
import math
import re
import numpy as np
import nltk
from nltk.corpus import stopwords

#nltk.download('stopwords')
def get_voc(texte):
    list_voc = np.array([])
    for i in texte :
        if i not in list_voc :
            list_voc = np.append(list_voc,i)

    return list_voc

def split_line(text):
    return text.split()


def PPMI_all(texte):
    taille_fenetre = 5
    stop_words = stopwords.words('french')
    print(stop_words)
    dic_ppmi = {}
    nb_mot = 0
    nb_appa = {}
    # nb_fenêtres = len(texte) - taille_fenêtre
    # Parcours de la totalité du texte

    for mot in texte :
        if mot.lower() not in stop_words:
            nb_appa[mot] = 0
            dic_ppmi[mot] = {}
    for indice_x in range(len(texte)):


        #Tant qu'on ne dépasse pas du texte

        if indice_x+taille_fenetre-1 <= len(texte):


            # On ne considère pas les stopwords
            if texte[indice_x] not in stop_words:
                if texte[indice_x] not in nb_appa:
                    nb_appa[texte[indice_x]] = 1
                else :
                    nb_appa[texte[indice_x]] += 1
 #               if texte[indice_x] not in dic_ppmi:
#                    dic_ppmi[texte[indice_x]]={}
                #On considère les (taille_fenêtre-1) mots suivants sans considérer le premier mot
                for i in range(taille_fenetre-1):
                    if texte[indice_x + i+1] in dic_ppmi[texte[indice_x]]:
                        # Apparitions conjointes
                        dic_ppmi[texte[indice_x]][texte[indice_x + i+1]] += 1
                        dic_ppmi[texte[indice_x + i+1]][texte[indice_x]] += 1
                        nb_mot += 1
                    else :
                        dic_ppmi[texte[indice_x]][texte[indice_x + i+1]] = 1
                        dic_ppmi[texte[indice_x + i+1]][texte[indice_x]] = 1
                        nb_mot += 1
    for mot in dic_ppmi:
        for mot_conj in dic_ppmi[mot]:
            pmot = nb_appa[mot]/nb_mot
            pmotconj = nb_appa[mot_conj]/nb_mot
            dic_ppmi[mot][dic_ppmi]=dic_ppmi[mot][dic_ppmi]/(pmot * pmotconj)

    return dic_ppmi
'''        
        
        else:
            break
    for curseur in range((len(texte)-1)):
        Tfxy = 0
        Tfx = 0
        Tfy = 0
        fenetre_aux=np.array([])
        for i in range(taille_fenetre):
            if i+curseur > len(texte)-1:
                break
            fenetre_aux = np.append(fenetre_aux, texte[i + curseur ])
        pas_vu = True
        for mot in fenetre_aux:
            if mot == x :
                Tfx += 1
            if mot == y :
                Tfy +=1
            if Tfx >= 1 and Tfy >= 1  and pas_vu  :
                Tfxy = 1
                pas_vu = False

        occur_x = np.append(occur_x, Tfx)
        occur_y = np.append(occur_y, Tfy)
        occur_xy = np.append(occur_xy, Tfxy)
    Tfxy = 0
    Tfy=0
    Tfx=0
    for apparition in occur_x :
        Tfx += apparition
    for apparition in occur_y :
        Tfy += apparition
    for apparition in occur_xy :
        Tfxy += apparition
    occurences_total = Tfx + Tfy
    Pxy = Tfxy / len(occur_x)
    Px = Tfx / len(occur_x)
    Py = Tfy / len(occur_x)
    base_log = 10
    if (Pxy / (Px * Py)) > 0:
        pmi = math.log((Pxy / (Px * Py)), base_log)
    else :
        return 0
    if pmi > 0:
        return pmi
    else:
        return 0
'''


def PPMI (x, y, texte):
    # INITIALISATION
    # print(x+" "+ y)

    # Taille des fenêtres de mots
    taille_fenetre=5

    # Vecteurs d'occurence de X, de Y et d'occurrences simultannées de X et Y
    occur_x = np.array([])
    occur_y = np.array([])
    occur_xy = np.array([])

    # BODY
    # Début lecture texte
    # Pour un curseur allant de 0 à taille(texte)-1
    # (-1 car les tableaux commencent à 0 et non à 1)
    for curseur in range((len(texte)-1)):

        # Remise à 0 des compteurs d'occurences de (X,Y), X et Y
        Tfxy = 0
        Tfx = 0
        Tfy = 0
        # Fenêtre glissante
        fenetre_aux=np.array([])

        # Construction des fenêtres
        # On veut récupérer les 5 mots du texte à partir du curseurs soit :
        # fenetre_aux = [texte[curseur],texte[curseur+1],texte[curseur+2],texte[curseur+3],texte[curseur+4]]

        # Pour i allant de 0 à la taille de la fenêtre
        for i in range(taille_fenetre):
            # Si le curseur dépasse du texte
            # len(texte)-1 : les indices commencent à 0 tandis que la taille commence à 1
            # donc il faut soustraire 1 pour que cela coïncide
            if i+curseur > len(texte)-1:
                # On sort
                break
            # Ajout du mot dans la fenêtre
            fenetre_aux = np.append(fenetre_aux, texte[i + curseur ])
        # Remise à 0 du booléen
        pas_vu = True
        # Pour tous les mots de la fenêtre actuelle
        for mot in fenetre_aux:

            # Si le mot considéré est le mot X
            if mot == x :
                # Incrémentation du compteur de X
                Tfx += 1

            # Si le mot considéré est le mot Y
            if mot == y :
                # Incrémentation du compteur de Y
                Tfy +=1
            # Si le mot X et le mot Y ont été rencontré dans cette fenêtre
            # et si c'est la première fois qu'ils ont été compté
            if Tfx >= 1 and Tfy >= 1  and pas_vu  :
                # On met le compte à 1
                Tfxy = 1
                # On indique que le mot a déjà été compté
                pas_vu = False

        # Soit notre fenêtre glissantes :
        # fenêtre = [mot1, mot2, mot3, mot4, mot5]

        # Ajout du nombre d'apparition de x et y dans leur vecteur correspondants
        occur_x = np.append(occur_x, Tfx)
        occur_y = np.append(occur_y, Tfy)
        # Ajout du nombre d'apparition conjointes de x et y
        occur_xy = np.append(occur_xy, Tfxy)

    # Réinitialisation des compteurs
    Tfxy = 0
    Tfy=0
    Tfx=0

    #print(occur_x)
    #print(occur_y)
    #print(occur_xy)
    # Comptage du total d'apparition de X dans les N contextes
    for apparition in occur_x :
        Tfx += apparition
    # Comptage du total d'apparition de Y dans les N contextes
    for apparition in occur_y :
        Tfy += apparition
    # Comptage du total d'apparition conjointe de X et Y dans les N contextes
    for apparition in occur_xy :
        Tfxy += apparition

    # Compteur du nombre d'occurences de X et Y
    occurences_total = Tfx + Tfy
    #print(occurences_total)
    #print(str(Tfxy) + " / " + str(occurences_total) )
    '''
        # Sont-ce les bonnes formules à appliquer ? Pas certain !
        # Probabilité d'avoir X et Y (correspond à la fréquence de (X,Y) ?)
        Pxy = Tfxy / occurences_total
        print("Pxy =" + str(Pxy))
        # Probabilité d'avoir X  (correspond à la fréquence de X ?)
        Px = Tfx / occurences_total
        print("Px =" + str(Px))
        # Probabilité d'avoir Y  (correspond à la fréquence de Y ?)
        Py = Tfy / occurences_total
        print("Py =" + str(Py))
        base_log = 10
        pmi = math.log((Pxy / (Px * Py)), base_log)
        print((Pxy / (Px * Py)))
    '''
    # Version 2 :
    #print(Tfxy)
    #print("Tfx ")
    #print(Tfx)
    #print("Tfy ")
    #print(Tfy)

    Pxy = Tfxy / len(occur_x)
    #print("Pxy =" + str(Pxy))
    # Probabilité d'avoir X  (correspond à la fréquence de X ?)
    Px = Tfx / len(occur_x)
    #print("Px =" + str(Px))
    # Probabilité d'avoir Y  (correspond à la fréquence de Y ?)
    Py = Tfy / len(occur_x)
    #print("Py =" + str(Py))
    base_log = 10
    if (Pxy / (Px * Py)) > 0:
        pmi = math.log((Pxy / (Px * Py)), base_log)
    else :
        return 0
    #print((Pxy / (Px * Py)))
    if pmi > 0:
        return pmi
    else:
        return 0






text = "A chaque ville, son explication. Les gares sur l’axe Atlantique (Toulouse, " \
       "Tours et Bordeaux) ont par exemple été touchées par les travaux de la LGV Sud-Europe Atlantique, " \
       "reliant Paris à Bordeaux en 2h04, inaugurée au début du mois de juillet." \
       " Toulouse, relié à Paris via Bordeaux en TGV, a donc fait les frais de cette entreprise, débutée en 2012."

# Suppression de tous les caractères qui ne sont pas : de a à z, de A à Z,
# de 0 à 9, de "à" à "é", de "é" à "è" (cf codage ASCII)
text_aux = re.sub(r"[^a-zA-Z0-9-à-é-è]+", ' ', text)
print(text_aux)
text_formate = split_line(text_aux)
print(text_formate)

res = PPMI("Bordeaux","Toulouse",text_formate)
#print(res)

# Permet d'obtenir le vocabulaire du texte :
# la liste des mots uniques du texte
voc = get_voc(text_formate)
print(len(voc))
print(PPMI_all(text_formate))
'''
import numpy as np
import matplotlib.pyplot as plt
from sklearn.decomposition import PCA
X = matrice
pca = PCA(n_components=2)
Xp = pca.fit_transform(X)
red = [0,1,2]
bleu = [3,4,5]
plt.plot([x[0] for x in Xp[red]],[x[1] for x in Xp[red]], 'ro')
plt.plot([x[0] for x in Xp[bleu]],[x[1] for x in Xp[bleu]], 'bx')
plt.axis([1.5, 3.5, 0, 0.3])
plt.savefig('foo.png')

'''
''' # Je sais plus à quoi sert cette partie 
def ESA(u,v):
    print(u)
    print(v)
    return np.dot(u,v)/(np.linalg.norm(u) * np.linalg.norm(v))


matrice = np.zeros((len(voc),len(voc)))
for i in range(len(voc) -1):
    for j in range(len(voc)-1):
        if(i!= j):
            matrice[i][j] = ESA(voc[i],voc[j])
print(matrice)
'''